{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAtack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8uT_x-GILnn",
        "outputId": "bbf881d7-5512-4dc7-a159-f9cbc190468e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PrPF2KRdINmL",
        "outputId": "4d465d4d-880e-47a2-f6a2-3fe2679712b0"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.34.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=64a856dce8137e0c7f2b08d8c8cf6cc0ff53e54deafe0303ae5e9c01dba32723\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcasWglGISM5",
        "outputId": "d0306bad-367f-4899-9a13-d7c61f60cc2a"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VlgNQkbIVRz"
      },
      "source": [
        "import csv\n",
        "from numpy import moveaxis\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorflow.python.keras.utils import np_utils\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWYIDkJOIVwV",
        "outputId": "fa6040b9-4e50-4f75-873a-8f88a465e255"
      },
      "source": [
        "cd '/content/gdrive/My Drive/Colab Notebooks/cleverhans'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YwMxqRY3IXat",
        "outputId": "f57c574a-424d-4e92-8aa4-644b149f2ebc"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/cleverhans'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Eqf3mqIZqH"
      },
      "source": [
        "import cleverhans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVLr7u2UIbVQ"
      },
      "source": [
        "# Dont run again\n",
        "   # !pip install tensorflow==1.13.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb7ro_FMIczb",
        "outputId": "775604d0-6874-4adb-b18c-430be506b037"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import logging\n",
        "import numpy as np\n",
        "from six.moves import xrange\n",
        "import tensorflow as tf\n",
        "\n",
        "from cleverhans.attacks import SaliencyMapMethod\n",
        "from cleverhans.compat import flags\n",
        "from cleverhans.dataset import MNIST\n",
        "from cleverhans.loss import CrossEntropy\n",
        "from cleverhans.utils import other_classes, set_log_level\n",
        "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
        "from cleverhans.utils_tf import model_eval, model_argmax\n",
        "from cleverhans.train import train\n",
        "from cleverhans.model_zoo.basic_cnn import ModelBasicCNN\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/utils_tf.py:345: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-7UUxPAIfYt"
      },
      "source": [
        "\"\"\"\n",
        "This tutorial shows how to generate adversarial examples\n",
        "using JSMA in white-box setting.\n",
        "The original paper can be found at:\n",
        "https://arxiv.org/abs/1511.07528\n",
        "\"\"\"\n",
        "#pylint: disable=missing-docstring\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "from six.moves import xrange\n",
        "import tensorflow as tf\n",
        "import copy\n",
        "\n",
        "from cleverhans.attacks import SaliencyMapMethod\n",
        "from cleverhans.compat import flags\n",
        "from cleverhans.dataset import MNIST\n",
        "from cleverhans.loss import CrossEntropy\n",
        "from cleverhans.utils import other_classes, set_log_level\n",
        "from cleverhans.utils import pair_visual, grid_visual, AccuracyReport\n",
        "from cleverhans.utils_tf import model_eval, model_argmax\n",
        "from cleverhans.train import train\n",
        "from cleverhans.model_zoo.basic_cnn import ModelBasicCNN\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIV1DKK0Ii0G",
        "outputId": "61131897-144a-4117-ed6a-937a2169373f"
      },
      "source": [
        "FLAGS = flags.FLAGS\n",
        "\n",
        "VIZ_ENABLED = True\n",
        "NB_EPOCHS = 6\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = .001\n",
        "SOURCE_SAMPLES = 10\n",
        "\n",
        "train_start=0\n",
        "train_end=60000 \n",
        "test_start=0\n",
        "test_end=10000 \n",
        "viz_enabled=VIZ_ENABLED\n",
        "learning_rate=LEARNING_RATE\n",
        "def mnist_tutorial_jsma(train_start=0, train_end=60000, test_start=0,\n",
        "                        test_end=10000, viz_enabled=VIZ_ENABLED,\n",
        "                        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
        "                        source_samples=SOURCE_SAMPLES,\n",
        "                        learning_rate=LEARNING_RATE):\n",
        "  \"\"\"\n",
        "  MNIST tutorial for the Jacobian-based saliency map approach (JSMA)\n",
        "  :param train_start: index of first training set example\n",
        "  :param train_end: index of last training set example\n",
        "  :param test_start: index of first test set example\n",
        "  :param test_end: index of last test set example\n",
        "  :param viz_enabled: (boolean) activate plots of adversarial examples\n",
        "  :param nb_epochs: number of epochs to train model\n",
        "  :param batch_size: size of training batches\n",
        "  :param nb_classes: number of output classes\n",
        "  :param source_samples: number of test inputs to attack\n",
        "  :param learning_rate: learning rate for training\n",
        "  :return: an AccuracyReport object\n",
        "  \"\"\"\n",
        "  # Object used to keep track of (and return) key accuracies\n",
        "report = AccuracyReport()\n",
        "\n",
        "  # Set TF random seed to improve reproducibility\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "  # Create TF session and set as Keras backend session\n",
        "sess = tf.Session()\n",
        "print(\"Created TensorFlow session.\")\n",
        "\n",
        "set_log_level(logging.DEBUG)\n",
        "\n",
        "  # Get MNIST test data\n",
        "mnist = MNIST(train_start=train_start, train_end=train_end,test_start=test_start, test_end=test_end)\n",
        "x_train, y_train = mnist.get_set('train')\n",
        "x_test, y_test = mnist.get_set('test')\n",
        "\n",
        "  # Obtain Image Parameters\n",
        "img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
        "nb_classes = y_train.shape[1]\n",
        "\n",
        "  # Define input TF placeholder\n",
        "x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,nchannels))\n",
        "y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
        "\n",
        "nb_filters = 64\n",
        "  # Define TF model graph\n",
        "model = ModelBasicCNN('model1', nb_classes, nb_filters)\n",
        "preds = model.get_logits(x)\n",
        "loss = CrossEntropy(model, smoothing=0.1)\n",
        "print(\"Defined TensorFlow model graph.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created TensorFlow session.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py:35: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py:35: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py:36: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/initializers.py:13: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/initializers.py:21: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/initializers.py:22: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py:40: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py:41: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model.py:129: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "Defined TensorFlow model graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "7y5NhSSIIk4V",
        "outputId": "23a9eb65-a161-45d8-9513-a4343d0d4992"
      },
      "source": [
        "  #########################################################################\n",
        "  # Training the model using TensorFlow\n",
        "  ###########################################################################\n",
        "\n",
        "  # Train an MNIST model\n",
        "  reuse=tf.AUTO_REUSE\n",
        "  reuse=True\n",
        "  train_params = {\n",
        "      'nb_epochs': 10,\n",
        "      'batch_size': 128,\n",
        "      'learning_rate': 0.001\n",
        "  }\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  rng = np.random.RandomState([2017, 8, 30])\n",
        "  train(sess, loss, x_train, y_train, args=train_params, rng=rng)\n",
        "  # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
        "  eval_params = {'batch_size': 128}\n",
        "  accuracy = model_eval(sess, x, y, preds, x_test, y_test, args=eval_params)\n",
        "  assert x_test.shape[0] == test_end - test_start, x_test.shape\n",
        "  print('Test accuracy on legitimate test examples: {0}'.format(accuracy))\n",
        "  report.clean_train_clean_eval = accuracy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-bd4e3b76467d>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    sess.run(tf.global_variables_initializer())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nWFZWG-oImut",
        "outputId": "aa36c312-4d74-4d41-cafc-d9eb6e04968b"
      },
      "source": [
        " source_samples=SOURCE_SAMPLES\n",
        "  # Keep track of success (adversarial example classified in target)\n",
        " results = np.zeros((nb_classes, source_samples), dtype='i')\n",
        " perturbations = np.zeros((nb_classes, source_samples), dtype='f')\n",
        "  # Initialize our array for grid visualization\n",
        " grid_shape = (nb_classes, nb_classes, img_rows, img_cols, nchannels)\n",
        " grid_viz_data = np.zeros(grid_shape, dtype='f')\n",
        "    # Instantiate a SaliencyMapMethod attack object\n",
        " jsma = SaliencyMapMethod(model, sess=sess)\n",
        " jsma_params = {'theta': 1., 'gamma': 0.1,'clip_min': 0., 'clip_max': 1.,'y_target': None}\n",
        " figure = None\n",
        "    # Loop over the samples we want to perturb into adversarial examples\n",
        " for sample_ind in xrange(0, source_samples):\n",
        "    print('--------------------------------------')\n",
        "    print('Attacking input %i/%i' % (sample_ind + 1, source_samples))\n",
        "    sample = x_test[sample_ind:(sample_ind + 1)]\n",
        "    current_class = int(np.argmax(y_test[sample_ind]))\n",
        "    target_classes = other_classes(nb_classes, current_class)\n",
        "    grid_viz_data[current_class, current_class, :, :, :] = np.reshape(sample, (img_rows, img_cols, nchannels))\n",
        "    # Loop over all target classes\n",
        "    for target in target_classes:\n",
        "      print('Generating adv. example for target class %i' % target)\n",
        "      # This call runs the Jacobian-based saliency map approach\n",
        "      one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)\n",
        "      one_hot_target[0, target] = 1\n",
        "      jsma_params['y_target'] = one_hot_target\n",
        "      adv_x = jsma.generate_np(sample, **jsma_params)\n",
        "      # Check if success was achieved\n",
        "      res = int(model_argmax(sess, x, preds, adv_x) == target)\n",
        "      # Compute number of modified features\n",
        "      adv_x_reshape = adv_x.reshape(-1)\n",
        "      test_in_reshape = x_test[sample_ind].reshape(-1)\n",
        "      nb_changed = np.where(adv_x_reshape != test_in_reshape)[0].shape[0]\n",
        "      percent_perturb = float(nb_changed) / adv_x.reshape(-1).shape[0]\n",
        "      # Display the original and adversarial images side-by-side\n",
        "      if viz_enabled:\n",
        "        figure = pair_visual(np.reshape(sample, (img_rows, img_cols, nchannels)),np.reshape(adv_x, (img_rows, img_cols, nchannels)), figure)\n",
        "      # Add our adversarial example to our grid data\n",
        "      grid_viz_data[target, current_class, :, :, :] = np.reshape(adv_x, (img_rows, img_cols, nchannels))\n",
        "\n",
        "      # Update the arrays for later analysis\n",
        "      results[target, sample_ind] = res\n",
        "      perturbations[target, sample_ind] = percent_perturb\n",
        "\n",
        " print('--------------------------------------')\n",
        "\n",
        " # Compute the number of adversarial examples that were successfully found\n",
        " nb_targets_tried = ((nb_classes - 1) * source_samples)\n",
        " succ_rate = float(np.sum(results)) / nb_targets_tried\n",
        " print('Avg. rate of successful adv. examples {0:.4f}'.format(succ_rate))\n",
        " report.clean_train_adv_eval = 1. - succ_rate\n",
        "\n",
        "    # Compute the average distortion introduced by the algorithm\n",
        " percent_perturbed = np.mean(perturbations)\n",
        " print('Avg. rate of perturbed features {0:.4f}'.format(percent_perturbed))\n",
        "\n",
        "    # Compute the average distortion introduced for successful samples only\n",
        " percent_perturb_succ = np.mean(perturbations * (results == 1))\n",
        " print('Avg. rate of perturbed features for successful '\n",
        "          'adversarial examples {0:.4f}'.format(percent_perturb_succ))\n",
        "\n",
        "    # Close TF session\n",
        " sess.close()\n",
        "\n",
        "    # Finally, block & display a grid of all the adversarial examples\n",
        " if viz_enabled:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.close(figure)\n",
        "    _ = grid_visual(grid_viz_data)\n",
        "\n",
        "return report\n",
        "\n",
        "\n",
        "def main(argv=None):\n",
        "    mnist_tutorial_jsma(viz_enabled=FLAGS.viz_enabled,\n",
        "                        nb_epochs=FLAGS.nb_epochs,\n",
        "                        batch_size=FLAGS.batch_size,\n",
        "                        nb_classes=FLAGS.nb_classes,\n",
        "                        source_samples=FLAGS.source_samples,\n",
        "                        learning_rate=FLAGS.learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    flags.DEFINE_boolean('viz_enabled', True, 'Visualize adversarial ex.')\n",
        "    flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
        "    flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
        "    flags.DEFINE_integer('nb_classes', 10, 'Number of output classes')\n",
        "    flags.DEFINE_integer('source_samples', 10, 'Nb of test inputs to attack')\n",
        "    flags.DEFINE_float('learning_rate', 0.001, 'Learning rate for training')\n",
        "\n",
        "    tf.app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/attacks_tf.py:27: UserWarning: attacks_tf is deprecated and will be removed on 2019-07-18 or after. Code should import functions from their new locations directly.\n",
            "  warnings.warn(\"attacks_tf is deprecated and will be removed on 2019-07-18\"\n",
            "[INFO 2021-06-03 20:18:48,830 cleverhans] Constructing new graph for attack SaliencyMapMethod\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "Attacking input 1/10\n",
            "Generating adv. example for target class 0\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/attacks/saliency_map_method.py:246: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/attacks/saliency_map_method.py:247: The name tf.floordiv is deprecated. Please use tf.math.floordiv instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_sum_v1 at 0x7f28c80f60e0> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_max_v1 at 0x7f28c80fe320> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_any_v1 at 0x7f28c80fe9e0> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value model1/conv2d_2/kernel\n\t [[{{node model1/conv2d_2/kernel/read}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8905a404be1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m      \u001b[0mone_hot_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m      \u001b[0mjsma_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m      \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mjsma_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m      \u001b[0;31m# Check if success was achieved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m      \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/attacks/attack.py\u001b[0m in \u001b[0;36mgenerate_np\u001b[0;34m(self, x_val, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value model1/conv2d_2/kernel\n\t [[node model1/conv2d_2/kernel/read (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'model1/conv2d_2/kernel/read':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-3f91bff42c83>\", line 61, in <module>\n    model = ModelBasicCNN('model1', nb_classes, nb_filters)\n  File \"/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py\", line 26, in __init__\n    self.fprop(tf.placeholder(tf.float32, [128, 28, 28, 1]))\n  File \"/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/model_zoo/basic_cnn.py\", line 38, in fprop\n    y = my_conv(y, 2 * self.nb_filters, 5, strides=1, padding='valid')\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py\", line 424, in conv2d\n    return layer.apply(inputs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1700, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/base.py\", line 548, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\", line 165, in build\n    dtype=self.dtype)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/base.py\", line 461, in add_weight\n    **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py\", line 1872, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 203, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 4239, in identity\n    \"Identity\", input=input, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "LbJNDo0yIo8U",
        "outputId": "a42b4515-5279-4dec-b513-24f8d7a874e1"
      },
      "source": [
        " source_samples=SOURCE_SAMPLES\n",
        "  # Keep track of success (adversarial example classified in target)\n",
        " results = np.zeros((nb_classes, source_samples), dtype='i')\n",
        " perturbations = np.zeros((nb_classes, source_samples), dtype='f')\n",
        "  # Initialize our array for grid visualization\n",
        " grid_shape = (nb_classes, nb_classes, img_rows, img_cols, nchannels)\n",
        " grid_viz_data = np.zeros(grid_shape, dtype='f')\n",
        "    # Instantiate a SaliencyMapMethod attack object\n",
        " jsma = SaliencyMapMethod(model, sess=sess)\n",
        " jsma_params = {'theta': 1., 'gamma': 0.1,'clip_min': 0., 'clip_max': 1.,'y_target': None}\n",
        " figure = None\n",
        "    # Loop over the samples we want to perturb into adversarial examples\n",
        " for sample_ind in xrange(0, source_samples):\n",
        "    print('--------------------------------------')\n",
        "    print('Attacking input %i/%i' % (sample_ind + 1, source_samples))\n",
        "    sample = x_test[sample_ind:(sample_ind + 1)]\n",
        "    current_class = int(np.argmax(y_test[sample_ind]))\n",
        "    target_classes = other_classes(nb_classes, current_class)\n",
        "    grid_viz_data[current_class, current_class, :, :, :] = np.reshape(sample, (img_rows, img_cols, nchannels))\n",
        "    # Loop over all target classes\n",
        "    for target in target_classes:\n",
        "      print('Generating adv. example for target class %i' % target)\n",
        "      # This call runs the Jacobian-based saliency map approach\n",
        "      one_hot_target = np.zeros((1, nb_classes), dtype=np.float32)\n",
        "      one_hot_target[0, target] = 1\n",
        "      jsma_params['y_target'] = one_hot_target\n",
        "      adv_x = jsma.generate_np(sample, **jsma_params)\n",
        "      # Check if success was achieved\n",
        "      res = int(model_argmax(sess, x, preds, adv_x) == target)\n",
        "      # Compute number of modified features\n",
        "      adv_x_reshape = adv_x.reshape(-1)\n",
        "      test_in_reshape = x_test[sample_ind].reshape(-1)\n",
        "      nb_changed = np.where(adv_x_reshape != test_in_reshape)[0].shape[0]\n",
        "      percent_perturb = float(nb_changed) / adv_x.reshape(-1).shape[0]\n",
        "      # Display the original and adversarial images side-by-side\n",
        "      if viz_enabled:\n",
        "        figure = pair_visual(np.reshape(sample, (img_rows, img_cols, nchannels)),np.reshape(adv_x, (img_rows, img_cols, nchannels)), figure)\n",
        "      # Add our adversarial example to our grid data\n",
        "      grid_viz_data[target, current_class, :, :, :] = np.reshape(adv_x, (img_rows, img_cols, nchannels))\n",
        "\n",
        "      # Update the arrays for later analysis\n",
        "      results[target, sample_ind] = res\n",
        "      perturbations[target, sample_ind] = percent_perturb\n",
        "\n",
        " print('--------------------------------------')\n",
        "\n",
        "  # Compute the number of adversarial examples that were successfully found\n",
        " nb_targets_tried = ((nb_classes - 1) * source_samples)\n",
        " succ_rate = float(np.sum(results)) / nb_targets_tried\n",
        " print('Avg. rate of successful adv. examples {0:.4f}'.format(succ_rate))\n",
        " report.clean_train_adv_eval = 1. - succ_rate\n",
        "  # Compute the average distortion introduced by the algorithm\n",
        " percent_perturbed = np.mean(perturbations[np.where(perturbations!=0)])\n",
        " print('Avg. rate of perturbed features {0:.4f}'.format(percent_perturbed))\n",
        "  # Compute the average distortion introduced for successful samples only\n",
        " percent_perturb_succ = np.mean(perturbations[np.where(perturbations!=0)] * (results[np.where(perturbations!=0)] == 1))\n",
        " print('Avg. rate of perturbed features for successful ','adversarial examples {0:.4f}'.format(percent_perturb_succ))\n",
        " sess.close()\n",
        "  # Finally, block & display a grid of all the adversarial examples\n",
        " if viz_enabled:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.close(figure)\n",
        "    _ = grid_visual(grid_viz_data)\n",
        "return report\n",
        "\n",
        "def main(argv=None):\n",
        "  from cleverhans_tutorials import check_installation\n",
        "  check_installation(__file__)\n",
        "\n",
        "  mnist_tutorial_jsma(viz_enabled=FLAGS.viz_enabled,\n",
        "                      nb_epochs=FLAGS.nb_epochs,\n",
        "                      batch_size=FLAGS.batch_size,\n",
        "                      source_samples=FLAGS.source_samples,\n",
        "                      learning_rate=FLAGS.learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  flags.DEFINE_boolean('viz_enabled', VIZ_ENABLED,\n",
        "                       'Visualize adversarial ex.')\n",
        "  flags.DEFINE_integer('nb_epochs', NB_EPOCHS,\n",
        "                       'Number of epochs to train model')\n",
        "  flags.DEFINE_integer('batch_size', BATCH_SIZE, 'Size of training batches')\n",
        "  flags.DEFINE_integer('source_samples', SOURCE_SAMPLES,\n",
        "                       'Nb of test inputs to attack')\n",
        "  flags.DEFINE_float('learning_rate', LEARNING_RATE,\n",
        "                     'Learning rate for training')\n",
        "\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 2021-06-03 19:50:56,208 cleverhans] Constructing new graph for attack SaliencyMapMethod\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------\n",
            "Attacking input 1/10\n",
            "Generating adv. example for target class 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_sum_v1 at 0x7f776cb2c0e0> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_max_v1 at 0x7f776cb33320> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_any_v1 at 0x7f776cb339e0> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d02875ad8851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m      \u001b[0mone_hot_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m      \u001b[0mjsma_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m      \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mjsma_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m      \u001b[0;31m# Check if success was achieved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m      \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_argmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/My Drive/Colab Notebooks/cleverhans/cleverhans/attacks/attack.py\u001b[0m in \u001b[0;36mgenerate_np\u001b[0;34m(self, x_val, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    }
  ]
}